<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
  <meta charset="utf-8">
  <meta name="generator" content="quarto-0.9.178">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Oregon Extended Assessment Technical Documentation - 4&nbsp; Technical Quality: Other</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>

  <script src="site_libs/quarto-nav/quarto-nav.js"></script>
  <script src="site_libs/quarto-nav/headroom.min.js"></script>
  <script src="site_libs/clipboard/clipboard.min.js"></script>
  <meta name="quarto:offset" content="./">
  <script src="site_libs/quarto-search/autocomplete.umd.js"></script>
  <script src="site_libs/quarto-search/fuse.min.js"></script>
  <script src="site_libs/quarto-search/quarto-search.js"></script>
  <link href="./ce5.html" rel="next">
  <link href="./ce3.html" rel="prev">
  <script src="site_libs/quarto-html/quarto.js"></script>
  <script src="site_libs/quarto-html/popper.min.js"></script>
  <script src="site_libs/quarto-html/tippy.umd.min.js"></script>
  <script src="site_libs/quarto-html/anchor.min.js"></script>
  <link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
  <link id="quarto-text-highlighting-styles" href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
  <script src="site_libs/bootstrap/bootstrap.min.js"></script>
  <link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
  <link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
  <script id="quarto-search-options" type="application/json">{
    "location": "sidebar",
    "copy-button": false,
    "collapse-after": 3,
    "panel-placement": "start",
    "type": "textbox",
    "limit": 20,
    "language": {
      "search-no-results-text": "No results",
      "search-matching-documents-text": "matching documents",
      "search-copy-link-title": "Copy link to search",
      "search-hide-matches-text": "Hide additional matches",
      "search-more-match-text": "more match in this document",
      "search-more-matches-text": "more matches in this document",
      "search-clear-button-title": "Clear",
      "search-detached-cancel-button-title": "Cancel",
      "search-submit-button-title": "Submit"
    }
  }</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body class="floating">
<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Technical Quality: Other</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Oregon Extended Assessment Technical Documentation</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/UO-BRT/orext-techreport-template" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="./Oregon-Extended-Assessment-Technical-Documentation.pdf" title="Download PDF" class="sidebar-tool px-1"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Introduction</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ce1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statewide System</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ce2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Assessment Operations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ce3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Technical Quality: Validity</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ce4.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Technical Quality: Other</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ce5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Inclusion of All Students</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ce6.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Standards and Reporting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Appendices</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Statewide System of Standards and Assessments</span></a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#reliability" class="nav-link active" data-scroll-target="#reliability"> <span class="header-section-number">4.1</span> 4.1 Reliability</a>
<ul class="collapse">
<li><a href="#a-test-reliability" class="nav-link" data-scroll-target="#a-test-reliability"> <span class="header-section-number">4.1.1</span> 4.1A Test Reliability</a></li>
<li><a href="#test-information-functions" class="nav-link" data-scroll-target="#test-information-functions"> <span class="header-section-number">4.1.2</span> Test Information Functions</a></li>
<li><a href="#english-language-arts-tifs" class="nav-link" data-scroll-target="#english-language-arts-tifs"> <span class="header-section-number">4.1.3</span> English Language Arts TIFs</a></li>
<li><a href="#mathematics-tifs" class="nav-link" data-scroll-target="#mathematics-tifs"> <span class="header-section-number">4.1.4</span> Mathematics TIFs</a></li>
<li><a href="#science-tifs" class="nav-link" data-scroll-target="#science-tifs"> <span class="header-section-number">4.1.5</span> Science TIFs</a></li>
<li><a href="#validation-of-orext-vertical-scales" class="nav-link" data-scroll-target="#validation-of-orext-vertical-scales"> <span class="header-section-number">4.1.6</span> Validation of ORExt Vertical Scales</a></li>
<li><a href="#b-overall-and-conditional-standard-errors-of-measure" class="nav-link" data-scroll-target="#b-overall-and-conditional-standard-errors-of-measure"> <span class="header-section-number">4.1.7</span> 4.1B Overall and Conditional Standard Errors of Measure</a></li>
<li><a href="#c-classification-accuracy-consistency" class="nav-link" data-scroll-target="#c-classification-accuracy-consistency"> <span class="header-section-number">4.1.8</span> 4.1C Classification Accuracy &amp; Consistency</a></li>
</ul></li>
<li><a href="#fairness-and-accessibility" class="nav-link" data-scroll-target="#fairness-and-accessibility"> <span class="header-section-number">4.2</span> 4.2 Fairness and Accessibility</a>
<ul class="collapse">
<li><a href="#differential-item-functioning-analyses" class="nav-link" data-scroll-target="#differential-item-functioning-analyses"> <span class="header-section-number">4.2.1</span> Differential Item Functioning Analyses</a></li>
<li><a href="#race---ethnicity-percentages-and-totals-by-content-area-and-grade-level" class="nav-link" data-scroll-target="#race---ethnicity-percentages-and-totals-by-content-area-and-grade-level"> <span class="header-section-number">4.2.2</span> Race - Ethnicity Percentages and Totals by Content Area and Grade Level</a></li>
<li><a href="#exceptionality-percentages-by-content-area-and-grade-level" class="nav-link" data-scroll-target="#exceptionality-percentages-by-content-area-and-grade-level"> <span class="header-section-number">4.2.3</span> Exceptionality Percentages By Content Area and Grade Level</a></li>
<li><a href="#observed-means-and-standard-deviations" class="nav-link" data-scroll-target="#observed-means-and-standard-deviations"> <span class="header-section-number">4.2.4</span> Observed Means and Standard Deviations</a></li>
</ul></li>
<li><a href="#full-performance-continuum" class="nav-link" data-scroll-target="#full-performance-continuum"> <span class="header-section-number">4.3</span> 4.3 Full Performance Continuum</a>
<ul class="collapse">
<li><a href="#english-language-arts-personitem-distributions" class="nav-link" data-scroll-target="#english-language-arts-personitem-distributions"> <span class="header-section-number">4.3.1</span> English Language Arts Person/Item Distributions</a></li>
<li><a href="#mathematics-personitem-distributions" class="nav-link" data-scroll-target="#mathematics-personitem-distributions"> <span class="header-section-number">4.3.2</span> Mathematics Person/Item Distributions</a></li>
<li><a href="#science-personitem-distributions" class="nav-link" data-scroll-target="#science-personitem-distributions"> <span class="header-section-number">4.3.3</span> Science Person/Item Distributions</a></li>
</ul></li>
<li><a href="#scoring" class="nav-link" data-scroll-target="#scoring"> <span class="header-section-number">4.4</span> 4.4 Scoring</a></li>
<li><a href="#multiple-assessment-forms" class="nav-link" data-scroll-target="#multiple-assessment-forms"> <span class="header-section-number">4.5</span> 4.5 Multiple Assessment Forms</a></li>
<li><a href="#multiple-versions-of-an-assessment" class="nav-link" data-scroll-target="#multiple-versions-of-an-assessment"> <span class="header-section-number">4.6</span> 4.6 Multiple Versions of An Assessment</a></li>
<li><a href="#technical-analyses-and-ongoing-maintenance" class="nav-link" data-scroll-target="#technical-analyses-and-ongoing-maintenance"> <span class="header-section-number">4.7</span> 4.7 Technical Analyses and Ongoing Maintenance</a></li>
</ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<header id="title-block-header" class="quarto-title-block default">

<div class="quarto-title"><h1 class="title d-none d-lg-block display-7"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Technical Quality: Other</span></h1></div></header>

<section id="reliability" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="reliability"><span class="header-section-number">4.1</span> 4.1 Reliability</h2>
<p>Test reliability can be viewed through several lenses, all of which document how consistently an assessment performs across occasions, contexts, and raters. Typical strategies for addressing reliability include documentation of internal consistency, split-half reliability, and test-retest reliability. If multiple forms are implemented, test form reliability documentation is also requisite. The implementation plan for the ORExt includes initial documentation of internal consistency (Cronbach’s alpha). The 2015-16 technical report included internal consistency estimates, split-half reliability analyses, as well as a small test-retest assessment of reliability comparisons by means of our pilot tablet administration study. There is only one test form for the ORExt, so test form comparisons are not possible.</p>
<section id="a-test-reliability" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="a-test-reliability"><span class="header-section-number">4.1.1</span> 4.1A Test Reliability</h3>
<p>Marginal reliability results (true score variance/true score variance + error variance) demonstrate that the tests are quite reliable at the total test level. Full reliability statistics for each of the operational tests administered this year are provided below. These results demonstrate that the total test reliabilities were quite high, ranging from .67 to .91. Each table below provides the content area, grade, and the marginal reliabilities. All test forms were composed of 36 operational and 12 embedded field-test items.</p>
<div class="cell">

</div>
</section>
<section id="test-information-functions" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="test-information-functions"><span class="header-section-number">4.1.2</span> Test Information Functions</h3>
<p>The test information functions published below also indicate that the scales exhibit a reliability greater than or equal to .80 for all proficient-level cutscores.</p>
</section>
<section id="english-language-arts-tifs" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="english-language-arts-tifs"><span class="header-section-number">4.1.3</span> English Language Arts TIFs</h3>
<div class="cell">

</div>
</section>
<section id="mathematics-tifs" class="level3" data-number="4.1.4">
<h3 data-number="4.1.4" class="anchored" data-anchor-id="mathematics-tifs"><span class="header-section-number">4.1.4</span> Mathematics TIFs</h3>
<div class="cell">

</div>
</section>
<section id="science-tifs" class="level3" data-number="4.1.5">
<h3 data-number="4.1.5" class="anchored" data-anchor-id="science-tifs"><span class="header-section-number">4.1.5</span> Science TIFs</h3>
<div class="cell">

</div>
</section>
<section id="validation-of-orext-vertical-scales" class="level3" data-number="4.1.6">
<h3 data-number="4.1.6" class="anchored" data-anchor-id="validation-of-orext-vertical-scales"><span class="header-section-number">4.1.6</span> Validation of ORExt Vertical Scales</h3>
<p>The Test Characteristic Curves (TCCs) for the grade-level assessments in ELA and mathematics demonstrate incrementally increasing growth and test demands across Grades 3-8, with the exception of Grade 7 mathematics. The Grade 7 mathematics assessment was revised to be more difficult last year, but clearly more elaboration of this effort is needed to address its location on the TCC. Grade 11 and science tests are not vertically scaled; TCCs are thus not presented for Grade 11 or science. All Rasch model scaling, as well as the data visualizations for the TCCs were conducted in the R software 3.3.2 environment (R Core Team, 2016) using the r2Winsteps package (Anderson, 2015).</p>
<div class="cell">

</div>
</section>
<section id="b-overall-and-conditional-standard-errors-of-measure" class="level3" data-number="4.1.7">
<h3 data-number="4.1.7" class="anchored" data-anchor-id="b-overall-and-conditional-standard-errors-of-measure"><span class="header-section-number">4.1.7</span> 4.1B Overall and Conditional Standard Errors of Measure</h3>
<p>The average SEM associated with each cut score for 2017-18 student data are presented in the table below, supported by a KEY. The SEMs decreased in almost all cases compared to last year, suggesting that the measures are more reliable when student eligibility is more strictly controlled. See Section 4.2 below for means and standard deviations by grade and subject area. SEM = Standard Error of Measure associated with the cut score to the left; averaged to the tenths’ place. Level 1 = Does Not Yet Meet (not included as the lowest level of proficiency) Level 2 = Nearly Meets Level 3 = Meets Level 4 = Exceeds</p>
<div class="cell">

</div>
</section>
<section id="c-classification-accuracy-consistency" class="level3" data-number="4.1.8">
<h3 data-number="4.1.8" class="anchored" data-anchor-id="c-classification-accuracy-consistency"><span class="header-section-number">4.1.8</span> 4.1C Classification Accuracy &amp; Consistency</h3>
<p>Results from the 2017-18 ORExt test administration were analyzed using Rudner’s classification index <span class="citation" data-cites="rudner05">(<a href="references.html#ref-rudner05" role="doc-biblioref">Rudner 2005</a>)</span>. Results closer to 1.0 indicate the likelihood that a student was appropriately classified as proficient or not proficient (accuracy) and the likelihood that the student would be classified in the same category given an additional test administration. The calculation utilizes item difficulty and theta value distributions, as well as related standard errors of measurement, to generate probabilistic estimates based on one test administration. Complete results, generated from the cacIRT package in R, are provided below. Results denote very high levels of classification accuracy and consistency.</p>
<div class="cell">

</div>
<p>The ORExt is not a computer-adaptive instrument so estimate precision documentation based upon that test design is not provided.</p>
</section>
</section>
<section id="fairness-and-accessibility" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="fairness-and-accessibility"><span class="header-section-number">4.2</span> 4.2 Fairness and Accessibility</h2>
<p>The state has taken steps to ensure fairness in the development of the assessments, including an analysis of each test item by Oregon teachers not only for linkage to standards, but also for access, sensitivity, and bias (see <em>Appendix</em> 3.1A). In addition, we reviewed test functioning as relevant to race/ethnicity and disability subgroups. This process increases the likelihood that students are receiving instruction in areas reflected in the assessment, and also that the items are not biased toward a particular demographic or sub-group.</p>
<section id="differential-item-functioning-analyses" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="differential-item-functioning-analyses"><span class="header-section-number">4.2.1</span> Differential Item Functioning Analyses</h3>
<p>To investigate Differential Item Functioning (DIF), the Mantel-Haenszel test using a purification process was conducted <span class="citation" data-cites="holland88 kamata04">(<a href="references.html#ref-holland88" role="doc-biblioref">Holland and Thayer 1988</a>; <a href="references.html#ref-kamata04" role="doc-biblioref">Kamata and Vaughn 2004</a>)</span> with the R software using the difR package (Magis et al., 2013). When using the Mantel-Haenszel test to investigate DIF, contingency tables are constructed, and the resulting odds for the focal group answering the item correctly are compared to the odds for the reference group. Given n-size limitations (Scott, et al., 2009), we were able to conduct two analyses: a) White/Non-White and b) Male/Female. Whites and Males were the focal groups and Non-Whites and Females were the reference groups, respectively. The contingency table summarizes correct and incorrect responses to each item by respondents’ total raw score by subgroup (Kamata &amp; Vaughn, 2004). If there is no difference in performance for the two groups, the odds ratio of the focal group performance to reference group performance will equal one. An odds ratio greater than one means the focal group is performing better than the reference group, with the opposite being true for odds ratios less than one.</p>
<p>The difR package contains a built in algorithm to conduct purification automatically, so we were interested in how this algorithm functioned relative to the iterations conducted manually using SPSS. We used criteria outlined by the Educational Testing Service (ETS) for DIF Classification (Holland &amp; Thayer, 1988) to determine whether or not items exhibited DIF, as the difR package reports delta values by default, defined as <span class="math display">\[\Delta_{MH} =
-2.35*ln(\alpha_{MH})\]</span></p>
<p>The Holland and Thayer criteria were used for all Mantel-Haenszel analyses. Items that were flagged as “C” level items were reviewed by BRT researchers for potential biases. If biases are identified, the item is removed from the item pool. DIF analyses were performed ex post facto on the 2015-16 ORExt operational items to address longitudinal trends. Only three ELA items were identified as exhibiting a “C” level DIF across both 2017 and 2018. Those three ELA items, one in Grade 5 that exhibited DIF that privileged White examinees, one in Grade 4 that privileged Female examinees, and one in Grade 8 that privileged Female examinees, were removed and were not used in 2017-18 or thereafter. DIF analyses was also be performed in the 2017-18 school year to continue to address DIF longitudinally. All items, including field test items, were included in the analyses. There are a total of 48 items on each assessment.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DIF Grades
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>A: <span class="math inline">\(0 &gt; \delta &lt;= 1\)</span></li>
<li>B: <span class="math inline">\(1 &gt; \delta &lt;= 1.5\)</span></li>
<li>C: <span class="math inline">\(1.5 &gt; \delta\)</span></li>
</ul>
</div>
</div>
<p>Within the White/Non-White analysis, 10 out of 18 items flagged as “C” level items privileged Non-White test participants in ELA, 2 out of 5 privileged Non-White test participants in Mathematics, and 2 out of 7 privileged Non-White test participants in Science. Overall, DIF flagging bases on race was relatively balanced, with 14 privileging students who were Non-White and 16 privileging students who were White.</p>
<div class="cell">

</div>
<p>In terms of the Male/Female analyses, 10 out of 16 items flagged as “C” level items privileged Females in ELA, 4 out of 9 flagged items privileged Females in Mathematics, and 8 out of 11 flagged items privileged Females in Science. Overall, DIF flagging based on sex was relatively balanced, with 22 privileging Females and 14 privileging Males.</p>
<div class="cell">

</div>
</section>
<section id="race---ethnicity-percentages-and-totals-by-content-area-and-grade-level" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="race---ethnicity-percentages-and-totals-by-content-area-and-grade-level"><span class="header-section-number">4.2.2</span> Race - Ethnicity Percentages and Totals by Content Area and Grade Level</h3>
<p>The full ethnic and disability demographics for students taking the ORExt are reported below. Students ethnicity/race was reported in seven categories: (a) American Indian/Alaskan Native, (b) Asian, (c) Black or African-American, (d) Multi-ethnic, (e) Native Hawaiian or Other Pacific Islander, (f) Hispanic, or (g) White. The majority of students were reported as White (53-68%) or Hispanic (12-27%). These results are largely consistent with the demographics reported for the general assessments, though percentages taking the ORExt are slightly higher for most students of color and generally lower for students who are Asian or White (see <em>Appendix</em> 4.2).</p>
<div class="cell">

</div>
<p>The majority of students who participated in the ORExt were students with Intellectual Disability (30-45%) and students with Autism Spectrum Disorder (28 -34%), followed by students with Other Health Impairment (11-16%). ODE policy for 2015-16 changed to require students who participate in the ORExt to take the assessment in all relevant content areas. There is thus very little change in terms of participation percentages across content areas, as evidenced by the total n-sizes per grade level displayed below.</p>
</section>
<section id="exceptionality-percentages-by-content-area-and-grade-level" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="exceptionality-percentages-by-content-area-and-grade-level"><span class="header-section-number">4.2.3</span> Exceptionality Percentages By Content Area and Grade Level</h3>
<div class="cell">

</div>
</section>
<section id="observed-means-and-standard-deviations" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="observed-means-and-standard-deviations"><span class="header-section-number">4.2.4</span> Observed Means and Standard Deviations</h3>
<p>The following tables provide information regarding observed means and standard deviations by content area and grade level. The Grade 3-8 English language arts and mathematics scaled scores are centered on 200, while all Grade 11 scores are centered on 900 (to reinforce that they are not on the vertical scale). Science is centered on 500 at Grade 5 and centered on 800 at Grade 8. The vertically scaled scores generally convey incremental gains in achievement across grade levels, though the results suggest small losses across grades in math.These scales were selected to clearly determine whether scores are on the same scale and also to differentiate among the statewide assessments in use to avoid confusion (i.e., SBA, OAKS, ORExt, ELPA, KA). The general pattern is that RIT scores decreased from 2014-15 to 2015-16. This decrease is attributed not to the scale, nor to deceleration of growth, but to the substantive shift in the tested student population as a result of ODE eligibility guidelines. The scale from 2015-16 to 2016-17 appears to have stabilized because the student population tested was more consistent.</p>
<div class="cell">

</div>
<section id="observed-means-reported-by-sex" class="level4" data-number="4.2.4.1">
<h4 data-number="4.2.4.1" class="anchored" data-anchor-id="observed-means-reported-by-sex"><span class="header-section-number">4.2.4.1</span> Observed Means Reported by Sex</h4>
<p>The following tables provide information regarding average student performance by grade level and sex (Female/Male) in each of the content areas assessed on the ORExt. Significant differences based on a Welch two sample t-test are noted in Grades 5 and 12 in ELA, and Grade 8 in mathematics.</p>
<div class="cell">

</div>
</section>
<section id="observed-means-reported-by-race" class="level4" data-number="4.2.4.2">
<h4 data-number="4.2.4.2" class="anchored" data-anchor-id="observed-means-reported-by-race"><span class="header-section-number">4.2.4.2</span> Observed Means Reported by Race</h4>
<p>The following table provides information regarding average student performance by grade level and race/ethnicity in each of the content areas assessed on the ORExt.</p>
<div class="cell">

</div>
</section>
<section id="observed-means-reported-by-exceptionality-status" class="level4" data-number="4.2.4.3">
<h4 data-number="4.2.4.3" class="anchored" data-anchor-id="observed-means-reported-by-exceptionality-status"><span class="header-section-number">4.2.4.3</span> Observed Means Reported by Exceptionality Status</h4>
<p>The following table is a number key for <strong>Elibibility Codes:</strong></p>
<section id="eligibility-codes-list" class="level5" data-number="4.2.4.3.1">
<h5 data-number="4.2.4.3.1" class="anchored" data-anchor-id="eligibility-codes-list"><span class="header-section-number">4.2.4.3.1</span> Eligibility Codes List</h5>
<ul>
<li>0 Not Applicable</li>
<li>10 Intellectual Disability</li>
<li>20 Hearing Impairment</li>
<li>40 Vision Impairment</li>
<li>43 Deafblindness</li>
<li>50 Communication Disorder</li>
<li>60 Emotional Disturbance</li>
<li>70 Orthopedic Impairment</li>
<li>74 Traumatic Brain Injury</li>
<li>80 Other Health Impairment</li>
<li>82 Autism Spectrum Disorder</li>
<li>90 Specific Learning Disability</li>
</ul>
<p>The following tables provide information regarding average student performance by grade level and exceptionality category in each of the content areas assessed on the ORExt. Students with SLD were generally the highest performing group, though students with ED performed higher at certain grade levels/content areas. The lowest performing group was consistently students with VI.</p>
<div class="cell">

</div>
</section>
</section>
<section id="graphs-of-observed-means-by-disability" class="level4" data-number="4.2.4.4">
<h4 data-number="4.2.4.4" class="anchored" data-anchor-id="graphs-of-observed-means-by-disability"><span class="header-section-number">4.2.4.4</span> Graphs of Observed Means By Disability</h4>
<p>The graphs below convey information similar to that shared above in graphic form. The graphics include 95% confidence interval error bars, so determining which subgroups performed in a manner that is significantly better than others is readily apparent by looking at the location of the error bars. Error bars that do not overlap in terms of the y-scale are significantly different. Students with VI are again the lowest performing group. Students with SLD are consistently outperforming most peers. Students with VI are consistently the lowest performing group, which led to concerns regarding test accessibility.</p>
<div class="cell">

</div>
</section>
</section>
</section>
<section id="full-performance-continuum" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="full-performance-continuum"><span class="header-section-number">4.3</span> 4.3 Full Performance Continuum</h2>
<p>The ORExt is designed to sample the Common Core State Standards in English language arts (Reading, Writing, and Language) and Mathematics, as well as the Oregon Science Standards and Next Generation Science Standards in science in a purposive, validated manner. The ORExt test blueprints convey the balance of representation exhibited by the assessment (see <em>Appendix</em> 2.1B). These test blueprints are supported by the <a href="http://www.brtprojects.org/publications/training-modules">ORExt Extended Assessment Frameworks</a>, which define the assessable content on the ORExt that has been reduced in depth, breadth, and complexity (RDBC) using our defined process (see <em>Appendix</em> 2.3A.3). The decisions regarding which standards to target for essentialization, as well as the strength of linkage between the Essentialized Standards and the CCSS/ORSci/NGSS has been validated by Oregon teachers, as well (see <em>Appendix</em> 3.1A).</p>
<p>Though a simplified and standardized approach was taken to design items, and efficiency and access to the assessment increased for the majority of students (as evidenced by the decreased percentages of zero scores across all content areas), a small subgroup of students remains who cannot access an academic assessment. This is true even though items have been significantly RDBC at three levels of complexity (low-medium-high difficulty). As a response, ODE commissioned BRT to design and implement an observational rating scale for this group of very low-performing students, called the Oregon Observational Rating Assessment (ORora) for the spring 2016 administration. The ORora targets communication (expressive and receptive) and basic skills (attention/joint attention and mathematics) and provides documentation of student progress outside of our clearly defined academic domains.</p>
<p>Items on all assessments were scored on a 2-point scale, with 1 point awarded for a correct response and 0 points awarded for an incorrect response. Plots are provided below for each content area and grade level, including the person ability and item difficulty distributions. In general, the descriptive statistics suggest that the test had an appropriate range of item difficulties represented, from easy to difficult, with item difficulties generally ranging from -4.0 to +4.0 on the Rasch scale. The assessments performed as expected across all grades and content areas. The item person distributions provided below demonstrate that the ORExt is providing a performance continuum for students who participate.</p>
<section id="english-language-arts-personitem-distributions" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="english-language-arts-personitem-distributions"><span class="header-section-number">4.3.1</span> English Language Arts Person/Item Distributions</h3>
<div class="cell">

</div>
</section>
<section id="mathematics-personitem-distributions" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="mathematics-personitem-distributions"><span class="header-section-number">4.3.2</span> Mathematics Person/Item Distributions</h3>
<div class="cell">

</div>
</section>
<section id="science-personitem-distributions" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="science-personitem-distributions"><span class="header-section-number">4.3.3</span> Science Person/Item Distributions</h3>
<div class="cell">

</div>
</section>
</section>
<section id="scoring" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="scoring"><span class="header-section-number">4.4</span> 4.4 Scoring</h2>
<p>All scoring expectations for the ORExt are established within the Administration Manual (see <em>Appendix</em> 2.3, p.&nbsp;14). The scoring procedures for the new ORExt have been simplified, with students receiving a 0 for an incorrect response or a 1 for a correct response. Input from the field gathered from Consequential Validity studies demonstrates that the assessment scoring procedures are much more clear and easier to implement than prior scoring approaches (see <em>Appendix</em> 2.3B.10). BRT was also commissioned to develop a scaled score interpretation guide, which describes specific strategies for interpreting student test scores and sub-test scores in Reading and Writing, and Achievement Level Descriptors (ALDs) published within the Individual Student Reports (see <em>Appendix</em> 6.4C) for annual performance, growth, and as part of Essential Skills requirements for very low performing students (see <em>Appendix</em> 2.1A).</p>
</section>
<section id="multiple-assessment-forms" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="multiple-assessment-forms"><span class="header-section-number">4.5</span> 4.5 Multiple Assessment Forms</h2>
<p>The ORExt was administered in only form per subject area and grade level for the 2017-18 school year, with 36 operational items arranged in order of empirical difficulty and 12 embedded field test items.</p>
</section>
<section id="multiple-versions-of-an-assessment" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="multiple-versions-of-an-assessment"><span class="header-section-number">4.6</span> 4.6 Multiple Versions of An Assessment</h2>
<p>The ORExt is provided in the standard format, but is also available in Large Print and Brailled formats. Test content is identical across all three versions, with an occasional item being eliminated on the Braille version due to inaccessibility. These items do not count for or against the student in reporting. Substantive test comparability analyses are not feasible, given the small n-sizes of the samples involved in the alternative versions.</p>
</section>
<section id="technical-analyses-and-ongoing-maintenance" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="technical-analyses-and-ongoing-maintenance"><span class="header-section-number">4.7</span> 4.7 Technical Analyses and Ongoing Maintenance</h2>
<p>The ORExt technical analyses that document reliability and validity are included in this technical report (see Sections 3 and 4, respectively). ODE and BRT staff review these analyses annually. Necessary adjustments to the assessment are determined prior to implementation of the subsequent year’s work plan, which elaborates the areas of improvement as well as aspects of the testing program that will be maintained. This decision-making is supported by input from the field gathered from the Consequential Validity study (see <em>Appendix</em> 2.3B.10).</p>
<p>Within our system of ongoing improvement is continuation of the development of additional curricular and instructional resources. This addresses an area of concern expressed by stakeholders. Training modules and templates continue to be developed to connect assessment results from the ORExt and ORora with curricular resources and instructional strategies aligned to the standards.</p>



<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-holland88" class="csl-entry" role="doc-biblioentry">
Holland, PW, and DT Thayer. 1988. <span>“Differential Item Performances and the Mantel-Haenszel Procedure.”</span> <em>Test Validity</em>, 129–45.
</div>
<div id="ref-kamata04" class="csl-entry" role="doc-biblioentry">
Kamata, Akihito, and Brandon K Vaughn. 2004. <span>“An Introduction to Differential Item Functioning Analysis.”</span> <em>Learning Disabilities: A Contemporary Journal</em> 2 (2): 49–69.
</div>
<div id="ref-rudner05" class="csl-entry" role="doc-biblioentry">
Rudner, Lawrence M. 2005. <span>“Expected Classification Accuracy.”</span> <em>Practical Assessment, Research, and Evaluation</em> 10 (1): 13.
</div>
</div>
</section>
</main> <!-- /main -->
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    setTimeout(function() {
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ce3.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Technical Quality: Validity</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ce5.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Inclusion of All Students</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->


</body></html>